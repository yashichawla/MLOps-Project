# Break The Bot - MLOps Project

## 📌 Introduction

Large Language Models (LLMs) are increasingly deployed in real-world applications, but they remain vulnerable to jailbreaks and prompt-injection attacks.  
Our project, **Break The Bot**, aims to build an automated MLOps pipeline for continuous safety evaluation of LLMs.

### System will:

- Preprocess and run adversarial prompts
- Measure **Attack Success Rate (ASR)** and **Refusal Quality**
- Use **LLM-as-a-Judge** for automated scoring
- Store and visualize results on dashboards
- Integrate with **CI/CD pipelines** to block unsafe releases

### Team Members:

1. Anjali Pai
2. Atharv Talnikar
3. Nitya Ravi
4. Rahul Kulkarni
5. Taniksha Datar
6. Yashi Chawla

### Repository Structure

```plaintext
MLOps-Project/
├── dags/                              # Airflow DAGs (Python workflows)
│   └── salad_preprocess_dag.py
├── scripts/                           # Python preprocessing logic used in DAGs
│   └── preprocess_salad.py
├── airflow_artifacts/                 # Airflow logs & scheduler outputs (autogenerated; ignored by git)
│   └── logs/                          # mounted to /opt/airflow/logs in containers
├── data/
│   ├── tmp/salad/                     # Parquet checkpoint files generated by the DAG
│   └── processed/                     # Final cleaned CSV file
├── venv/                              # Python virtual environment (ignored in git)
├── .airflow.env                       # Airflow env vars for local (WSL) scripts (LF line endings!)
├── .gitignore                         # Ignore venv, logs, airflow runtime, data outputs, etc.
├── .dockerignore                      # Exclude venv/logs/.git from Docker build context
├── docker-compose.yml                 # Postgres + Airflow (init/webserver/scheduler) stack
├── requirements.txt                   # Local (WSL) dev deps
├── requirements-docker.txt            # Container-friendly deps (pinned for Airflow providers)
├── setup_airflow.sh                   # One-time local (WSL) install & DB init
├── start_airflow.sh                   # Start local (WSL) webserver + scheduler
├── stop_airflow.sh                    # Stop local (WSL) Airflow processes
├── pyproject.toml                     # Editable install for local dev (`pip install -e .`)
└── README.md                          # Project + Airflow/Docker usage docs
```

### Setup Instructions:

1. Clone Repository

```bash
git clone https://github.com/yashichawla/MLOps-Project
cd MLOps-Project
```

2. Create Virtual Environment

```bash
   python -m venv venv
   source venv/bin/activate # On Mac/Linux
   venv\Scripts\activate # On Windows
```

3. Install Dependencies

```bash
   pip install -r requirements.txt
```

4. Run with Docker

```bash
   docker-compose up --build
```

### Features:

- Prompt Generator: Generates adversarial prompts using attacker LLMs.
- Evaluator Service: Runs prompts against target models and logs results.
- Judge Service: Scores responses for safety and refusal quality.
- Dashboards: Grafana visualizations for safety trends, ASR, and alerts.
- CI/CD Integration: Blocks unsafe deployments if safety metrics fail.
- Failure Analysis: Clustering and regression testing of jailbreak cases.

### Key Metrics:

- Attack Success Rate (ASR) - % of successful jailbreaks.
- Refusal Quality - judged clarity and robustness of refusals.
- Coverage Metrics - number and diversity of tested adversarial prompts.

### Project Timeline:

- Week 1-2: Repo setup, governance policy, seed prompt generation.
- Week 3-4: Prompt generator + evaluator API.
- Week 5-6: Judge API + calibration with human labels.
- Week 7-8: Dashboards, monitoring, failure analysis.
- Week 9-10: CI/CD gates, final validation, and reporting.

### First time setup w Airflow if running without Docker

```bash
chmod +x setup_airflow.sh start_airflow.sh stop_airflow.sh
./setup_airflow.sh
```

#### Start Airflow

```bash
./start_airflow.sh
```

This:

- Activates venv
- Loads .airflow.env (paths and config)

Starts:

- Webserver on http://localhost:8080
- Scheduler in background

### Setting up and running airflow w Docker (recommended)

```bash
# Navigate to project root
cd MLOps-Project

# (Optional but recommended) Create logs folder
mkdir -p airflow_artifacts/logs

# Initialize Airflow database + admin user in Docker
docker compose run --rm airflow-init
# Only for setup, after that just need to use compose up

#Start Airflow (Webserver + Scheduler + Postgres)
docker compose up -d webserver scheduler
```

Then open the UI:

📍 http://localhost:8080

👤 Username: admin
🔑 Password: admin

(This can be changed in docker-compose later if needed.)

To stop services but keep the database & logs:

```bash
docker compose down
```

To stop and remove everything (Postgres DB, logs, container volumes):

```bash
docker compose down -v       # removes DB volume
rm -rf airflow_artifacts/logs/*
```
